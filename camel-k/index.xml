<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Camel-K Integration on RHTE 2023 Edge Lab</title><link>https://RHTE-2023-Edge-Lab.github.io/camel-k/</link><description>Recent content in Camel-K Integration on RHTE 2023 Edge Lab</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://RHTE-2023-Edge-Lab.github.io/camel-k/index.xml" rel="self" type="application/rss+xml"/><item><title>Create a Kafka User (duo C)</title><link>https://RHTE-2023-Edge-Lab.github.io/camel-k/camel-user/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://RHTE-2023-Edge-Lab.github.io/camel-k/camel-user/</guid><description>Create a Kafka User for Camel K Integration.
Fist create a secret containing the Kafka User password.
To do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.
kind: Secret apiVersion: v1 metadata: name: camel-user stringData: password: s3cr3t type: Opaque Then create the Kafka user for the Camel K Integration. You can use the OpenShift console as used in the previous step.</description></item><item><title>Create a Kamelet (duo C)</title><link>https://RHTE-2023-Edge-Lab.github.io/camel-k/kamelet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://RHTE-2023-Edge-Lab.github.io/camel-k/kamelet/</guid><description>Create a Kamelet to able Camel K to connect your Kafka cluster.
To do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.
apiVersion: camel.apache.org/v1alpha1 kind: Kamelet metadata: name: kafka-sink-scram annotations: camel.apache.org/kamelet.support.level: &amp;#34;Stable&amp;#34; camel.apache.org/catalog.version: &amp;#34;main-SNAPSHOT&amp;#34; camel.apache.org/kamelet.icon: &amp;#34;data:image/svg+xml;base64,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&amp;#34; camel.apache.org/provider: &amp;#34;Apache Software Foundation&amp;#34; camel.apache.org/kamelet.group: &amp;#34;Kafka&amp;#34; labels: camel.apache.org/kamelet.type: &amp;#34;sink&amp;#34; spec: definition: title: &amp;#34;Kafka Sink (SCRAM Authentication)&amp;#34; description: |-Send data to Kafka topics.</description></item><item><title>Create Camel K integration for incoming parcels (duo C)</title><link>https://RHTE-2023-Edge-Lab.github.io/camel-k/integration-in/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://RHTE-2023-Edge-Lab.github.io/camel-k/integration-in/</guid><description>Create the camel Integration for the incoming parcels.
To do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.
apiVersion: camel.apache.org/v1 kind: Integration metadata: name: kafkaintegration-in spec: sources: - content: |from(&amp;#34;paho:esp8266-in?brokerUrl=tcp://mqtt-mqtt-0-svc:1883&amp;amp;userName=admin&amp;amp;password=public&amp;#34;) .setHeader(&amp;#34;key&amp;#34;).simple(&amp;#34;${bodyAs(String)}&amp;#34;) .convertBodyTo(String.class) .setBody({ e -&amp;gt; [ parcelNumber: e.in.body, timestamp: new Date().getTime() ] }) .marshal().json() //.to(&amp;#34;log:info&amp;#34;) .to(&amp;#34;kamelet:kafka-sink-scram?bootstrapServers=warehouse-kafka-bootstrap:9092&amp;amp;user=camel&amp;amp;password=s3cr3t&amp;amp;topic=warehouse-in&amp;#34;) name: mqtt-kafka.groovy traits: {}</description></item><item><title>Create Camel K integration for outcoming parcels (duo C)</title><link>https://RHTE-2023-Edge-Lab.github.io/camel-k/integration-out/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://RHTE-2023-Edge-Lab.github.io/camel-k/integration-out/</guid><description>Create the camel Integration for the outcoming parcels.
To do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.
apiVersion: camel.apache.org/v1 kind: Integration metadata: name: kafkaintegration-out spec: sources: - content: |from(&amp;#34;paho:esp8266-out?brokerUrl=tcp://mqtt-mqtt-0-svc:1883&amp;amp;userName=admin&amp;amp;password=public&amp;#34;) .setHeader(&amp;#34;key&amp;#34;).simple(&amp;#34;${bodyAs(String)}&amp;#34;) .convertBodyTo(String.class) .setBody({ e -&amp;gt; [ parcelNumber: e.in.body, timestamp: new Date().getTime() ] }) .marshal().json() //.to(&amp;#34;log:info&amp;#34;) .to(&amp;#34;kamelet:kafka-sink-scram?bootstrapServers=warehouse-kafka-bootstrap:9092&amp;amp;user=camel&amp;amp;password=s3cr3t&amp;amp;topic=warehouse-out&amp;#34;) name: mqtt-kafka.groovy traits: {}</description></item><item><title>Final verification (duo C)</title><link>https://RHTE-2023-Edge-Lab.github.io/camel-k/verification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://RHTE-2023-Edge-Lab.github.io/camel-k/verification/</guid><description>Camel Integration Navigate in the OpenShift Administrator console, Operators &amp;gt; Installed Operators. Click on the Red Hat Integration - Camel K operator. Open the Integration tab. Select the Current namespace only option. Make sure you have the following objects: Kafka User Navigate in the OpenShift Administrator console, Operators &amp;gt; Installed Operators. Click on the Red Hat Integration - AMQ Streams operator. Open the Kafka User tab. Select the Current namespace only option.</description></item><item><title>Test the Camel K Integrations (duo C)</title><link>https://RHTE-2023-Edge-Lab.github.io/camel-k/test/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://RHTE-2023-Edge-Lab.github.io/camel-k/test/</guid><description>Go to the OpenShift Administrator console and click the command line terminal icon in the top-right corner to open a Web Terminal.
Copy and paste the following commands to retrieve events from your Kafka topics.
Connect to one of your kafka pod oc rsh warehouse-kafka-0 Create a client.properties file cat &amp;lt;&amp;lt;EOF&amp;gt; /tmp/client.properties sasl.mechanism=SCRAM-SHA-512 security.protocol=SASL_PLAINTEXT sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \ username=&amp;#34;mm2&amp;#34; \ password=&amp;#34;s3cr3t&amp;#34;; EOF Connect to your warehouse-in Kafka topic to see your incoming parcels.</description></item></channel></rss>