[{"uri":"https://RHTE-2023-Edge-Lab.github.io/use-case/","title":"Use Case","tags":[],"description":"","content":"Chapter 1 Use case You and your team are part of the FSC (Fedora Shipping Company), a company that provides shipping and delivery services in EMEA.\nCurrently, the company has one Headquarter and ten Warehouses spread across Europe.\nYou and your team (watch around you, there are people around your table!) have been hired to setup the required IT infrastructure to track parcels along their journey.\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/use-case/goal/","title":"Goal","tags":[],"description":"","content":"Your goal will be to deploy everything needed to: read the parcel RFID (using arduino and ESP32), send data to a MQTT broker over wifi, transform those data using Camel-K and send relevant events over Kafka to the headquarter for reporting.\nThe headquarter is already setup and is waiting for your data!\nOnce your setup is complete, you should be able to scan your parcels (look around you, there should be four parcels on your table!) and see them move over the global map.\n  "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/camel-k/camel-user/","title":"Create a Kafka User (duo C)","tags":[],"description":"","content":"Create a Kafka User for Camel K Integration.\nFist create a secret containing the Kafka User password.\nTo do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.\nkind: Secret apiVersion: v1 metadata: name: camel-user stringData: password: s3cr3t type: Opaque Then create the Kafka user for the Camel K Integration. You can use the OpenShift console as used in the previous step.\napiVersion: kafka.strimzi.io/v1beta2 kind: KafkaUser metadata: name: camel labels: strimzi.io/cluster: warehouse spec: authentication: password: valueFrom: secretKeyRef: name: camel-user key: password type: scram-sha-512 "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-in/fix-permissions/","title":"Fix permissions on /dev/ttyUSB0 (Linux only)","tags":[],"description":"","content":"The /dev/ttyUSB0 device belongs to the \u0026ldquo;dialout\u0026rdquo; group. Therefore, your user should belong to this group to configure the ESP8266.\nRun this command:\nsudo usermod -a -G dialout $(id -un) Then, close Visual Studio Code and re-run it with the new group membership:\nsu -c code $(id -un) "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-out/fix-permissions/","title":"Fix permissions on /dev/ttyUSB0 (Linux only)","tags":[],"description":"","content":"The /dev/ttyUSB0 device belongs to the \u0026ldquo;dialout\u0026rdquo; group. Therefore, your user should belong to this group to configure the ESP8266.\nRun this command:\nsudo usermod -a -G dialout $(id -un) Then, close Visual Studio Code and re-run it with the new group membership:\nsu -c code $(id -un) "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/kafka-broker/kafka-cluster/","title":"Install the Kafka Broker (duo C)","tags":[],"description":"","content":"Deploy the Kafka Broker in your namespace by creating 2 Custom Resource Definitions (CRD).\nFirst create a secret containing the Certificate Authority (CA).\nTo do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.\nkind: Secret apiVersion: v1 metadata: name: warehouse-cluster-ca labels: strimzi.io/cluster: warehouse strimzi.io/kind: Kafka data: ca.key: \u0026gt;- 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 type: Opaque --- kind: Secret apiVersion: v1 metadata: name: warehouse-cluster-ca-cert labels: strimzi.io/cluster: warehouse strimzi.io/kind: Kafka data: ca.crt: \u0026gt;- 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 ca.p12: \u0026gt;- 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 ca.password: Q1NqSTlVMjFJb0ZK type: Opaque Then add the CRD that create the Kafka Cluster.\nTo do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.\napiVersion: kafka.strimzi.io/v1beta2 kind: Kafka metadata: name: warehouse spec: clusterCa: generateCertificateAuthority: false kafka: config: offsets.topic.replication.factor: 3 transaction.state.log.replication.factor: 3 transaction.state.log.min.isr: 2 default.replication.factor: 3 min.insync.replicas: 2 inter.broker.protocol.version: \u0026#39;3.2\u0026#39; storage: type: ephemeral listeners: - authentication: type: scram-sha-512 name: plain port: 9092 type: internal tls: false - authentication: type: scram-sha-512 name: tls port: 9093 type: route tls: true version: 3.2.3 replicas: 3 entityOperator: topicOperator: {} userOperator: {} zookeeper: storage: type: ephemeral replicas: 3 "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/mqtt-broker/mqtt-broker/","title":"Install the MQTT Broker (duo A or B)","tags":[],"description":"","content":"Deploy an MQTT broker in your namespace, by deploying this Custom Resource Definition.\nTo do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.\napiVersion: broker.amq.io/v1beta1 kind: ActiveMQArtemis metadata: name: mqtt spec: acceptors: - connectionsAllowed: 5 expose: true name: mqtt port: 1883 protocols: mqtt sslEnabled: false adminPassword: public adminUser: admin console: expose: true deploymentPlan: image: placeholder jolokiaAgentEnabled: false journalType: nio managementRBACEnabled: true messageMigration: false persistenceEnabled: false requireLogin: true size: 1 Now, create a new Kubernetes service to expose your MQTT broker to the internet. You can use the OpenShift console as used in the previous step.\napiVersion: v1 kind: Service metadata: name: mqtt-lb spec: ports: - name: mqtt-lb port: 1883 protocol: TCP targetPort: 1883 selector: ActiveMQArtemis: mqtt application: mqtt-app type: LoadBalancer "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/preparation/presentation/","title":"Present yourself!","tags":[],"description":"","content":" Fill-in the provided Name Tent templates with your name, role and location. Draw yourself as a Super Hero. Do not forget to draw your Fedora! Add a few super powers!  "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/use-case/architecture/","title":"Architecture","tags":[],"description":"","content":"Data flow 1. The ESP8266 scans incoming and outgoing parcels using an RFID scanner. One ESP8266 is dedicated for incoming parcels and one ESP8266 is dedicated for outgoing parcels.\n2. The ESP8266 dedicated to incoming parcels writes the RFID tag identifier in the mqtt-in MQTT topic. The ESP8266 dedicated to outgoing parcels writes the RFID tag identifier in the mqtt-out MQTT topic.\n3. The Camel K operator transforms and enriches MQTT messages stored in MQTT topics and injects those enriched data in the kafka-in and kafka-out Kafka topics.\n4. Kafka Mirror Maker mirrors in synchronous mode each topic of each warehouse (10) to the Kafka Broker running in the headquarter in order to centralize data.\n5. Camel Quarkus aggregates the mirrored topics of each warehouse in a single kafka topic, while enriching each event with metadata.\n6. Kafka Stream relies on a rocksdb database to retain the last known position of each parcel and send displacement event each time a move is detected. This information is sent in the shipment Kafka topic.\n7. A web front-end, based on Quarkus and connected to the shipment kafka topic, displays the moving parcels on a world map along with all warehouses.\nRed Hat Products  The MQTT Broker is provided by Red Hat AMQ Broker The Kafka Broker is provided by Red Hat AMQ Streams The Camel-K integration is provided by Red Hat Integration The Kafka Mirror Maker is provided by Red Hat AMQ Streams Kafka Streams is provided by Quarkus (Tech Preview) Quarkus is provided by Red Hat OpenShift Container Platform  Currently, this lab is hosted on RHPDS because of logistics and expenses considerations but:\n The headquarter could be deployed on a Managed Services offering of OpenShift (ROSA or ARO) The warehouses could be deployed on a Single Node OpenShift or Compact Cluster  "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-in/connect-esp8266/","title":"Connect your ESP8266","tags":[],"description":"","content":"Connect ESP8266 to your computer via USB connector.\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-out/connect-esp8266/","title":"Connect your ESP8266","tags":[],"description":"","content":"Connect ESP8266 to your computer via USB connector.\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/kafka-broker/kafka-user/","title":"Create a Kafka User (duo C)","tags":[],"description":"","content":"Create a Kafka User for your Kafka cluster as well as a secret containing its password. This Kafka User will be used by MirrorMaker2 deployed in the headquarter to authenticate to your namespaced Kafka Cluster.\nTo do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.\nkind: Secret apiVersion: v1 metadata: name: mm2-user stringData: password: s3cr3t type: Opaque --- apiVersion: kafka.strimzi.io/v1beta2 kind: KafkaUser metadata: labels: strimzi.io/cluster: warehouse name: mm2 spec: authentication: password: valueFrom: secretKeyRef: key: password name: mm2-user type: scram-sha-512 "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/camel-k/kamelet/","title":"Create a Kamelet (duo C)","tags":[],"description":"","content":"Create a Kamelet to able Camel K to connect your Kafka cluster.\nTo do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.\napiVersion: camel.apache.org/v1alpha1 kind: Kamelet metadata: name: kafka-sink-scram annotations: camel.apache.org/kamelet.support.level: \u0026#34;Stable\u0026#34; camel.apache.org/catalog.version: \u0026#34;main-SNAPSHOT\u0026#34; camel.apache.org/kamelet.icon: \u0026#34;data:image/svg+xml;base64,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\u0026#34; camel.apache.org/provider: \u0026#34;Apache Software Foundation\u0026#34; camel.apache.org/kamelet.group: \u0026#34;Kafka\u0026#34; labels: camel.apache.org/kamelet.type: \u0026#34;sink\u0026#34; spec: definition: title: \u0026#34;Kafka Sink (SCRAM Authentication)\u0026#34; description: |-Send data to Kafka topics. The Kamelet is able to understand the following headers to be set: - `key` / `ce-key`: as message key - `partition-key` / `ce-partitionkey`: as message partition key Both the headers are optional. required: - topic - bootstrapServers - user - password type: object properties: topic: title: Topic Names description: Comma separated list of Kafka topic names type: string bootstrapServers: title: Bootstrap Servers description: Comma separated list of Kafka Broker URLs type: string securityProtocol: title: Security Protocol description: Protocol used to communicate with brokers. SASL_PLAINTEXT, PLAINTEXT, SASL_SSL and SSL are supported type: string default: SASL_PLAINTEXT saslMechanism: title: SASL Mechanism description: The Simple Authentication and Security Layer (SASL) Mechanism used.  type: string default: SCRAM-SHA-512 user: title: Username description: Username to authenticate to Kafka  type: string x-descriptors: - urn:camel:group:credentials password: title: Password description: Password to authenticate to kafka type: string format: password x-descriptors: - urn:alm:descriptor:com.tectonic.ui:password - urn:camel:group:credentials dependencies: - \u0026#34;camel:core\u0026#34; - \u0026#34;camel:kafka\u0026#34; - \u0026#34;camel:kamelet\u0026#34; template: from: uri: \u0026#34;kamelet:source\u0026#34; steps: - choice: when: - simple: \u0026#34;${header[key]}\u0026#34; steps: - set-header: name: kafka.KEY simple: \u0026#34;${header[key]}\u0026#34; - simple: \u0026#34;${header[ce-key]}\u0026#34; steps: - set-header: name: kafka.KEY simple: \u0026#34;${header[ce-key]}\u0026#34; - choice: when: - simple: \u0026#34;${header[partition-key]}\u0026#34; steps: - set-header: name: kafka.PARTITION_KEY simple: \u0026#34;${header[partition-key]}\u0026#34; - simple: \u0026#34;${header[ce-partitionkey]}\u0026#34; steps: - set-header: name: kafka.PARTITION_KEY simple: \u0026#34;${header[ce-partitionkey]}\u0026#34; - to: uri: \u0026#34;kafka:{{topic}}\u0026#34; parameters: brokers: \u0026#34;{{bootstrapServers}}\u0026#34; securityProtocol: \u0026#34;{{securityProtocol}}\u0026#34; saslMechanism: \u0026#34;{{saslMechanism}}\u0026#34; saslJaasConfig: \u0026#34;org.apache.kafka.common.security.scram.ScramLoginModule required username=\u0026#39;{{user}}\u0026#39; password=\u0026#39;{{password}}\u0026#39;;\u0026#34; "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/mqtt-broker/mqtt-topic-in/","title":"Create the incoming MQTT Topic (duo A)","tags":[],"description":"","content":"Create a topic in your MQTT broker by deploying this Custom Resource Definition.\nTo do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.\nkind: ActiveMQArtemisAddress apiVersion: broker.amq.io/v1beta1 metadata: name: esp8266-in spec: addressName: esp8266-in queueName: myQueue0 routingType: anycast "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/pre-requisites/linux/","title":"Linux","tags":[],"description":"","content":"OpenShift CLI Install VScode.\nsudo rpm --import https://packages.microsoft.com/keys/microsoft.asc sudo sh -c \u0026#39;echo -e \u0026#34;[code]\\nname=Visual Studio Code\\nbaseurl=https://packages.microsoft.com/yumrepos/vscode\\nenabled=1\\ngpgcheck=1\\ngpgkey=https://packages.microsoft.com/keys/microsoft.asc\u0026#34; \u0026gt; /etc/yum.repos.d/vscode.repo\u0026#39; dnf check-update sudo dnf install code Install the PlatformIO IDE plugin for VScode with the following command:\ncode --install-extension platformio.platformio-ide "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/preparation/duo/","title":"Pair up!","tags":[],"description":"","content":"For the rest of this Lab, you will work in pair programming. With your team members, pair up and assign roles!\n Duo A is in charge of implementing the code on ESP8266 to scan the incoming parcels using RFID and send the data over MQTT. Duo B is in charge of implementing the code on ESP8266 to scan the outgoing parcels using RFID and send the data over MQTT. Duo C is in charge of setting up Kafka Broker and implementing the Camel-K integration.  At the end, you should have three pairs (or duos).\nTip: On your name tent, write your duo\u0026rsquo;s name (A, B or C)!\nNow, pick up the tasks assigned to your duo in the left menu!\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/preparation/","title":"Preparation","tags":[],"description":"","content":"Preparation Now that you know what you will do collaboratively, it\u0026rsquo;s time to know each other and organize yourself as a team!\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/use-case/organization/","title":"Organization","tags":[],"description":"","content":"At your table, there should be six persons and there should be ten tables. During this lab, you will work in pair programming (that is to say: three duo).\n Duo A is in charge of implementing the code on ESP8266 to scan the incoming parcels using RFID and send the data over MQTT. Duo B is in charge of implementing the code on ESP8266 to scan the outgoing parcels using RFID and send the data over MQTT. Duo C is in charge of setting up Kafka Broker and implementing the Camel-K integration.  "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-in/create-project/","title":"Create a PlatformIO project","tags":[],"description":"","content":"Open VScode and click on the home icon in the status bar. Restart your VSCode if the home icon does not appear.\nThen, in the PlatformIO splash screen (PIO HOME tab), click New Project.\nThen choose a name for your project (free choice), select the board WeMos D1 R2 and mini, leave the Arduino framework selected and click Finish.\nThen, you should see the following files in the left pane of your VScode.\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-out/create-project/","title":"Create a PlatformIO project","tags":[],"description":"","content":"Open VScode and click on the home icon in the status bar. Restart your VSCode if the home icon does not appear.\nThen, in the PlatformIO splash screen (PIO HOME tab), click New Project.\nThen choose a name for your project (free choice), select the board WeMos D1 R2 and mini, leave the Arduino framework selected and click Finish.\nThen, you should see the following files in the left pane of your VScode.\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/camel-k/integration-in/","title":"Create Camel K integration for incoming parcels (duo C)","tags":[],"description":"","content":"Create the camel Integration for the incoming parcels.\nTo do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.\napiVersion: camel.apache.org/v1 kind: Integration metadata: name: kafkaintegration-in spec: sources: - content: |from(\u0026#34;paho:esp8266-in?brokerUrl=tcp://mqtt-mqtt-0-svc:1883\u0026amp;userName=admin\u0026amp;password=public\u0026#34;) .setHeader(\u0026#34;key\u0026#34;).simple(\u0026#34;${bodyAs(String)}\u0026#34;) .convertBodyTo(String.class) .setBody({ e -\u0026gt; [ parcelNumber: e.in.body, timestamp: new Date().getTime() ] }) .marshal().json() //.to(\u0026#34;log:info\u0026#34;) .to(\u0026#34;kamelet:kafka-sink-scram?bootstrapServers=warehouse-kafka-bootstrap:9092\u0026amp;user=camel\u0026amp;password=s3cr3t\u0026amp;topic=warehouse-in\u0026#34;) name: mqtt-kafka.groovy traits: {} "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/kafka-broker/kafka-topics/","title":"Create the incoming and outcoming Kafka Topics (duo C)","tags":[],"description":"","content":"Create the incoming and outcoming Kafka Topics by deploying these CRDs. One KafkaTopic is used for incoming parcels scanned by one of your ESP826. The other KafkaTopic is used for outcoming parcels scanned by the other ESP826.\nFirst create the KafkaTopic for incoming traffic.\nTo do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.\nkind: KafkaTopic apiVersion: kafka.strimzi.io/v1beta2 metadata: name: warehouse-in labels: strimzi.io/cluster: warehouse spec: config: retention.ms: 604800000 segment.bytes: 1073741824 Then create the KafkaTopic for outcoming traffic by using the OpenShift console in the same way as the previous step.\nkind: KafkaTopic apiVersion: kafka.strimzi.io/v1beta2 metadata: name: warehouse-out labels: strimzi.io/cluster: warehouse spec: config: retention.ms: 604800000 segment.bytes: 1073741824 "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/mqtt-broker/mqtt-topic-out/","title":"Create the outgoing MQTT Topic (duo B)","tags":[],"description":"","content":"Create a topic in your MQTT broker by deploying this Custom Resource Definition.\nTo do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.\nkind: ActiveMQArtemisAddress apiVersion: broker.amq.io/v1beta1 metadata: name: esp8266-out spec: addressName: esp8266-out queueName: myQueue0 routingType: anycast "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/pre-requisites/macos/","title":"MacOS","tags":[],"description":"","content":"Go to the VScode download page, download the MacOS package and install it.\nOpen VScode and install the PlatformIO IDE plugin.\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/pre-requisites/","title":"Pre Requisites","tags":[],"description":"","content":"Chapter 2 Pre-requisites Pick the section that matches your Operating System and install the pre-requisites.\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-in/libraries/","title":"Add required libraries","tags":[],"description":"","content":"Add the following libraries to your PlatformIO project.\nMFRC522  In the PlatformIO home screen, open Libraries. In the search field, type:  header:MFRC522.h  The first result should be MFRC522 by Miguel André Balboa. Click to open it.   Click Add to project   Click Add  PubSubClient  In the PlatformIO home screen, open Libraries. In the search field, type:  PubSubClient  The first result should be PubSubClient by Nick O\u0026rsquo;Leary. Click to open it.   Click Add to project Click Add  "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-out/libraries/","title":"Add required libraries","tags":[],"description":"","content":"Add the following libraries to your PlatformIO project.\nMFRC522  In the PlatformIO home screen, open Libraries. In the search field, type:  header:MFRC522.h  The first result should be MFRC522 by Miguel André Balboa. Click to open it.   Click Add to project   Click Add  PubSubClient  In the PlatformIO home screen, open Libraries. In the search field, type:  PubSubClient  The first result should be PubSubClient by Nick O\u0026rsquo;Leary. Click to open it.   Click Add to project Click Add  "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/kafka-broker/kafka-test/","title":"Check the Kafka broker deployment (duo C)","tags":[],"description":"","content":"Kafka pods Go to Workload \u0026gt; Pods and make sure you have similar pods running on your namespace.\nKafka instances  Navigate in the OpenShift Administrator console, Operators \u0026gt; Installed Operators. Click on the Red Hat Integration - AMQ Streams operator. Open the All instances tab. Select the Current namespace only option. Make sure you have the following objects:  "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/camel-k/integration-out/","title":"Create Camel K integration for outcoming parcels (duo C)","tags":[],"description":"","content":"Create the camel Integration for the outcoming parcels.\nTo do so, connect to the OpenShift console, select the namespace of your team and click the + button in the top-right corner. Then, copy and paste the following content.\napiVersion: camel.apache.org/v1 kind: Integration metadata: name: kafkaintegration-out spec: sources: - content: |from(\u0026#34;paho:esp8266-out?brokerUrl=tcp://mqtt-mqtt-0-svc:1883\u0026amp;userName=admin\u0026amp;password=public\u0026#34;) .setHeader(\u0026#34;key\u0026#34;).simple(\u0026#34;${bodyAs(String)}\u0026#34;) .convertBodyTo(String.class) .setBody({ e -\u0026gt; [ parcelNumber: e.in.body, timestamp: new Date().getTime() ] }) .marshal().json() //.to(\u0026#34;log:info\u0026#34;) .to(\u0026#34;kamelet:kafka-sink-scram?bootstrapServers=warehouse-kafka-bootstrap:9092\u0026amp;user=camel\u0026amp;password=s3cr3t\u0026amp;topic=warehouse-out\u0026#34;) name: mqtt-kafka.groovy traits: {} "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/mqtt-broker/verification/","title":"Final verification (duo A and B)","tags":[],"description":"","content":"Operator CRD  Navigate in the OpenShift Administrator console, Operators \u0026gt; Installed Operators. Click on the AMQ Broker for RHEL 8.x operator. Open the All instances tab. Select the Current namespace only option. Make sure you have the following objects:  Pods Go to Workload \u0026gt; Pods and make sure the pod mqtt-ss-0 is present.\nServices Go to Networking \u0026gt; Services and make sure a service named mqtt-lb is present.\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/mqtt-broker/","title":"MQTT Broker","tags":[],"description":"","content":"MQTT Broker In this section, Duo A and B will install and configure a MQTT broker.\nThis step corresponds to the part 2. of the global architectural schema:\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/use-case/openshift/","title":"OpenShift","tags":[],"description":"","content":"OpenShift cluster An OpenShift cluster is already deployed via RHPDS environment and \u0026ldquo;OpenShift 4.11 Workshop\u0026rdquo; service.\nNo action is required on your side.\nThe headquarter and warehouses have dedicated namespaces on this OpenShift cluster:\n headquarter warehouse-athens warehouse-brno warehouse-brussels warehouse-bucharest warehouse-dublin warehouse-lisboa warehouse-london warehouse-paris warehouse-stockolm warehouse-varsovia  OpenShift Operators All the needed operators are already installed on the Openshift cluster. In the rest of this Lab you will just need to consume the CRD provided by these operators.\n  Red Hat Integration - AMQ Broker for RHEL 8 (Multiarch)\nAMQ Broker Operator for RHEL 8 (Multiarch) provides the ability to deploy and manage stateful AMQ Broker broker clusters\n  Red Hat Integration - AMQ Streams\nRed Hat AMQ Streams is a massively scalable, distributed, and high performance data streaming platform based on the Apache Kafka® project. AMQ Streams provides an event streaming backbone that allows microservices and other application components to exchange data with extremely high throughput and low latency. The core capabilities include: * A pub/sub messaging model, similar to a traditional enterprise messaging system, in which application components publish and consume events to/from an ordered stream\n   The long term, fault-tolerant storage of events The ability for a consumer to replay streams of events The ability to partition topics for horizontal scalability    Red Hat Integration - Camel K\nRed Hat Integration - Camel K is a lightweight integration platform, born on Kubernetes, with serverless superpowers.\n  Web Terminal\nStart a Web Terminal in your browser with common CLI tools for interacting with the cluster. You have access to useful commands for this lab like oc, mosquitto and kcat.\nTo launch the web terminal, click the command line terminal icon \u0026gt;_ on the upper right of the console. This instance is automatically logged in with your credentials.\n  OpenShift cluster details   OCP Cluster console URL : https://console-openshift-console.apps.cluster-GUID.GUID.sandboxID.opentlc.com/dashboards\n  OCP Cluster API URL : https://api.cluster-GUID.GUID.sandboxID.opentlc.com:6443\n  There is a dedicated OpenShift user for each warehouse. On your table you will find a poster with the relevant information.\nTo connect to your Openshift cluster, click on the OCP Cluster console URL above and fill in your username and password. You will have acces to the Web Terminal by clicking on the \u0026gt;_ icon on the top right. The Web Terminal provides the oc client.\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/mqtt-broker/test/","title":"Test the MQTT broker (duo A and B)","tags":[],"description":"","content":"Go to the OpenShift Administrator console and click the command line terminal icon \u0026gt;_ in the top-right corner to open a Web Terminal. In the Web Terminal, open two tabs: one to send messages, one to receive messages.\nOn the first terminal, connect to your MQTT Broker to read incoming messages.\n# Get the load balancer URL generated from the service created LOAD_BALANCER_URL=$(oc get svc mqtt-lb -ojsonpath=\u0026#34;{.status.loadBalancer.ingress[0].hostname}\u0026#34;) # Subscribe to MQTT topic mosquitto_sub -t esp8266-in -h ${LOAD_BALANCER_URL} -p 1883 -u admin -P public On the second terminal, push new messages to your MQTT Broker.\n# Get the load balancer URL generated from the service created LOAD_BALANCER_URL=$(oc get svc mqtt-lb -ojsonpath=\u0026#34;{.status.loadBalancer.ingress[0].hostname}\u0026#34;) # Subscribe to MQTT topic for i in {1..200}; do mosquitto_pub -t esp8266-in -h ${LOAD_BALANCER_URL} -p 1883 -u admin -P public -m in$i; done Go back on the first terminal to check if you received messages.\nPress CTRL+C on the first terminal and do the same process to check your MQTT Broker for outcoming messages:\nOn the first terminal, connect to your MQTT Broker to read outcoming messages.\n# Get the load balancer URL generated from the service created LOAD_BALANCER_URL=$(oc get svc mqtt-lb -ojsonpath=\u0026#34;{.status.loadBalancer.ingress[0].hostname}\u0026#34;) # Subscribe to MQTT topic mosquitto_sub -t esp8266-out -h ${LOAD_BALANCER_URL} -p 1883 -u admin -P public On the second terminal, push new messages to your MQTT Broker.\n# Get the load balancer URL generated from the service created LOAD_BALANCER_URL=$(oc get svc mqtt-lb -ojsonpath=\u0026#34;{.status.loadBalancer.ingress[0].hostname}\u0026#34;) # Subscribe to MQTT topic for i in {1..200}; do mosquitto_pub -t esp8266-out -h ${LOAD_BALANCER_URL} -p 1883 -u admin -P public -m out$i; done Go back on the first terminal to check if you received messages.\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/pre-requisites/windows/","title":"Windows","tags":[],"description":"","content":"TODO\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-in/development/","title":"Develop the ESP8266 firmware","tags":[],"description":"","content":"In the left pane of VScode, click the top-left icon to diplay the project\u0026rsquo;s files.\nReplace the content of src/main.cpp with the following code.\nWarning: you will have to adapt the code a little bit. See below for explanations.\nYou need to retrieve the load balancer url of the MQTT service.\nGo to the OpenShift Administrator console and click the command line terminal icon \u0026gt;_ in the top-right corner to open a Web Terminal. Copy and paste this command into the Openshift Web Terminal.\noc get svc mqtt-lb -ojsonpath=\u0026#34;{.status.loadBalancer.ingress[0].hostname}\u0026#34; Copy the result of the previous command and adapt the code bellow.\n#include \u0026lt;Arduino.h\u0026gt;#include \u0026lt;SPI.h\u0026gt;#include \u0026lt;MFRC522.h\u0026gt;#include \u0026lt;ESP8266WiFi.h\u0026gt;#include \u0026lt;PubSubClient.h\u0026gt; MFRC522 mfrc522; WiFiClient espClient; PubSubClient client(espClient); //WIFI const char* ssid = \u0026#34;\u0026lt;wifi_ssid\u0026gt;\u0026#34;; // SSID Wifi const char* password = \u0026#34;\u0026lt;wifi_password\u0026gt;\u0026#34;; //mot de passe Wifi  // MQTT Broker const char *mqtt_broker = \u0026#34;\u0026lt;LB address for MQTT service\u0026gt;\u0026#34;; const char *mqtt_topic = \u0026#34;esp8266-in\u0026#34;; const char *mqtt_username = \u0026#34;admin\u0026#34;; const char *mqtt_password = \u0026#34;public\u0026#34;; const int mqtt_port = 1883; void setup() { Serial.begin(9600); // Initialize serial communications with the PC  while (!Serial); // Do nothing if no serial port is opened (added for Arduinos based on ATMEGA32U4)  Serial.println(\u0026#34;Initializing...\u0026#34;); SPI.begin(); // Init SPI bus  mfrc522.PCD_Init(); // Init MFRC522  delay(4); // Optional delay.  if (!mfrc522.PCD_PerformSelfTest()) { Serial.println(\u0026#34;MFRC522 not ready !\u0026#34;); } Serial.println(\u0026#34;Ready !\u0026#34;); // Wifi initialization  WiFi.mode(WIFI_STA); WiFi.begin(ssid, password); Serial.print(\u0026#34;Connecting to Wifi...\u0026#34;); while (WiFi.status() != WL_CONNECTED) { delay(500); Serial.print(\u0026#34;.\u0026#34;); } Serial.println(); Serial.print(\u0026#34;Connected, IP address: \u0026#34;); Serial.println(WiFi.localIP()); randomSeed(micros()); // MQTT initialization  client.setServer(mqtt_broker, mqtt_port); } void reconnect() { // Loop until we\u0026#39;re reconnected  while (!client.connected()) { Serial.print(\u0026#34;Attempting MQTT connection...\u0026#34;); // Create a random client ID  String clientId = \u0026#34;ESP8266Client-\u0026#34;; clientId += String(random(0xffff), HEX); // Attempt to connect  if (client.connect(clientId.c_str(), mqtt_username, mqtt_password)) { Serial.println(\u0026#34;connected to MQTT Broker\u0026#34;); } else { Serial.print(\u0026#34;failed, rc=\u0026#34;); Serial.print(client.state()); Serial.println(\u0026#34; try again in 5 seconds\u0026#34;); // Wait 5 seconds before retrying  delay(5000); } } } void loop() { // MQTT connection to the broker + protocol handling  if (!client.connected()) { reconnect(); } client.loop(); // Reset the loop if no new card present on the sensor/reader. This saves the entire process when idle.  if ( ! mfrc522.PICC_IsNewCardPresent()) { return; } // Select one of the cards  if ( ! mfrc522.PICC_ReadCardSerial()) { return; } // Compute and print UID  char uid[30]; char * buffer = uid; for (byte i = 0; i \u0026lt; mfrc522.uid.size; i++) { int n = sprintf(buffer, \u0026#34;%s%02x\u0026#34;, i \u0026gt; 0 ? \u0026#34;:\u0026#34; : \u0026#34;\u0026#34;, mfrc522.uid.uidByte[i]); if (n \u0026gt; 0) { buffer += n; } } Serial.println(uid); client.publish(mqtt_topic, uid); delay(500); } Compile your code Flash your ESP8266 with your code "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-out/development/","title":"Develop the ESP8266 firmware","tags":[],"description":"","content":"In the left pane of VScode, click the top-left icon to diplay the project\u0026rsquo;s files.\nReplace the content of src/main.cpp with the following code.\nWarning: you will have to adapt the code a little bit. See below for explanations.\nYou need to retrieve the load balancer url of the MQTT service.\nGo to the OpenShift Administrator console and click the command line terminal icon \u0026gt;_ in the top-right corner to open a Web Terminal. Copy and paste this command into the Openshift Web Terminal.\noc get svc mqtt-lb -ojsonpath=\u0026#34;{.status.loadBalancer.ingress[0].hostname}\u0026#34; Copy the result of the previous command and adapt the code bellow.\n#include \u0026lt;Arduino.h\u0026gt;#include \u0026lt;SPI.h\u0026gt;#include \u0026lt;MFRC522.h\u0026gt;#include \u0026lt;ESP8266WiFi.h\u0026gt;#include \u0026lt;PubSubClient.h\u0026gt; MFRC522 mfrc522; WiFiClient espClient; PubSubClient client(espClient); //WIFI const char* ssid = \u0026#34;\u0026lt;wifi_ssid\u0026gt;\u0026#34;; // SSID Wifi const char* password = \u0026#34;\u0026lt;wifi_password\u0026gt;\u0026#34;; //mot de passe Wifi  // MQTT Broker const char *mqtt_broker = \u0026#34;\u0026lt;LB address for MQTT service\u0026gt;\u0026#34;; const char *mqtt_topic = \u0026#34;esp8266-out\u0026#34;; const char *mqtt_username = \u0026#34;admin\u0026#34;; const char *mqtt_password = \u0026#34;public\u0026#34;; const int mqtt_port = 1883; void setup() { Serial.begin(9600); // Initialize serial communications with the PC  while (!Serial); // Do nothing if no serial port is opened (added for Arduinos based on ATMEGA32U4)  Serial.println(\u0026#34;Initializing...\u0026#34;); SPI.begin(); // Init SPI bus  mfrc522.PCD_Init(); // Init MFRC522  delay(4); // Optional delay.  if (!mfrc522.PCD_PerformSelfTest()) { Serial.println(\u0026#34;MFRC522 not ready !\u0026#34;); } Serial.println(\u0026#34;Ready !\u0026#34;); // Wifi initialization  WiFi.mode(WIFI_STA); WiFi.begin(ssid, password); Serial.print(\u0026#34;Connecting to Wifi...\u0026#34;); while (WiFi.status() != WL_CONNECTED) { delay(500); Serial.print(\u0026#34;.\u0026#34;); } Serial.println(); Serial.print(\u0026#34;Connected, IP address: \u0026#34;); Serial.println(WiFi.localIP()); randomSeed(micros()); // MQTT initialization  client.setServer(mqtt_broker, mqtt_port); } void reconnect() { // Loop until we\u0026#39;re reconnected  while (!client.connected()) { Serial.print(\u0026#34;Attempting MQTT connection...\u0026#34;); // Create a random client ID  String clientId = \u0026#34;ESP8266Client-\u0026#34;; clientId += String(random(0xffff), HEX); // Attempt to connect  if (client.connect(clientId.c_str(), mqtt_username, mqtt_password)) { Serial.println(\u0026#34;connected to MQTT Broker\u0026#34;); } else { Serial.print(\u0026#34;failed, rc=\u0026#34;); Serial.print(client.state()); Serial.println(\u0026#34; try again in 5 seconds\u0026#34;); // Wait 5 seconds before retrying  delay(5000); } } } void loop() { // MQTT connection to the broker + protocol handling  if (!client.connected()) { reconnect(); } client.loop(); // Reset the loop if no new card present on the sensor/reader. This saves the entire process when idle.  if ( ! mfrc522.PICC_IsNewCardPresent()) { return; } // Select one of the cards  if ( ! mfrc522.PICC_ReadCardSerial()) { return; } // Compute and print UID  char uid[30]; char * buffer = uid; for (byte i = 0; i \u0026lt; mfrc522.uid.size; i++) { int n = sprintf(buffer, \u0026#34;%s%02x\u0026#34;, i \u0026gt; 0 ? \u0026#34;:\u0026#34; : \u0026#34;\u0026#34;, mfrc522.uid.uidByte[i]); if (n \u0026gt; 0) { buffer += n; } } Serial.println(uid); client.publish(mqtt_topic, uid); delay(500); } Compile your code Flash your ESP8266 with your code "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/camel-k/verification/","title":"Final verification (duo C)","tags":[],"description":"","content":"Camel Integration  Navigate in the OpenShift Administrator console, Operators \u0026gt; Installed Operators. Click on the Red Hat Integration - Camel K operator. Open the Integration tab. Select the Current namespace only option. Make sure you have the following objects:  Kafka User  Navigate in the OpenShift Administrator console, Operators \u0026gt; Installed Operators. Click on the Red Hat Integration - AMQ Streams operator. Open the Kafka User tab. Select the Current namespace only option. Make sure you have the following object:  "},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-in/","title":"Program the ESP8266 [in]","tags":[],"description":"","content":"Program the ESP8266 In this section, duo A will develop a firmware for the ESP8266 in order to scan incoming parcels.\nThis step corresponds to the part 1. of the global architectural schema:\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-in/test/","title":"Test the ESP8266 firmware","tags":[],"description":"","content":" Connect to your ESP8266 console   Place an RFID tag on the reader Check that the tag id is printed on the console Check that the tag is also sent over Wifi to the MQTT broker:  Go to the OpenShift Administrator console and click the command line terminal icon \u0026gt;_ in the top-right corner to open a Web Terminal. Run the following commands:\n# Get the load balancer URL generated from the service created LOAD_BALANCER_URL=$(oc get svc mqtt-lb -ojsonpath=\u0026#34;{.status.loadBalancer.ingress[0].hostname}\u0026#34;) # Subscribe to MQTT topic mosquitto_sub -t esp8266-in -h ${LOAD_BALANCER_URL} -p 1883 -u admin -P public Place an RFID tag on the reader. You should see similar results as the following screenshot:\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-out/test/","title":"Test the ESP8266 firmware","tags":[],"description":"","content":" Connect to your ESP8266 console   Place an RFID tag on the reader Check that the tag id is printed on the console Check that the tag is also sent over Wifi to the MQTT broker:  Go to the OpenShift Administrator console and click the command line terminal icon \u0026gt;_ in the top-right corner to open a Web Terminal. Run the following commands:\n# Get the load balancer URL generated from the service created LOAD_BALANCER_URL=$(oc get svc mqtt-lb -ojsonpath=\u0026#34;{.status.loadBalancer.ingress[0].hostname}\u0026#34;) # Subscribe to MQTT topic mosquitto_sub -t esp8266-out -h ${LOAD_BALANCER_URL} -p 1883 -u admin -P public Place an RFID tag on the reader. You should see similar results as the following screenshot:\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/esp8266-out/","title":"Program the ESP8266 [out]","tags":[],"description":"","content":"Program the ESP8266 In this section, duo B will develop a firmware for the ESP8266 in order to scan outcoming parcels.\nThis step corresponds to the part 1. of the global architectural schema:\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/camel-k/test/","title":"Test the Camel K Integrations (duo C)","tags":[],"description":"","content":"Go to the OpenShift Administrator console and click the command line terminal icon \u0026gt;_ in the top-right corner to open a Web Terminal.\nCopy and paste the following commands to retrieve events from your Kafka topics.\n Connect to one of your kafka pod  oc rsh warehouse-kafka-0 Create a client.properties file  cat \u0026lt;\u0026lt;EOF\u0026gt; /tmp/client.properties sasl.mechanism=SCRAM-SHA-512 security.protocol=SASL_PLAINTEXT sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \\ username=\u0026#34;mm2\u0026#34; \\ password=\u0026#34;s3cr3t\u0026#34;; EOF Connect to your warehouse-in Kafka topic to see your incoming parcels. Scan the parcel RFID with your ESP8266 used for incoming parcels.  ./bin/kafka-console-consumer.sh --bootstrap-server warehouse-kafka-bootstrap:9092 --topic warehouse-in --consumer.config /tmp/client.properties --from-beginning Press CTRL + C and connect now to your warehouse-out Kafka topic to see your outcoming parcels. Scan the parcel RFID with your ESP8266 used for outcoming parcels.  ./bin/kafka-console-consumer.sh --bootstrap-server warehouse-kafka-bootstrap:9092 --topic warehouse-out --consumer.config /tmp/client.properties --from-beginning You should see similar results as the followings:\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/kafka-broker/","title":"Kafka Broker","tags":[],"description":"","content":"Kafka Broker In this section, Duo C will install and configure a Kafka broker.\nThis step corresponds to the part 4. of the global architectural schema:\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/camel-k/","title":"Camel-K Integration","tags":[],"description":"","content":"Deploy the Camel K Integration In this section, Duo C will create the Camel-K Integration.\nThe Camel K integration enable us to listen to a new event in the MQTT Broker, transform the body of the message, add a timestamp and finally send the transformed and enriched event to a Kafka Topic.\nThis step corresponds to the part 3. of the global architectural schema:\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/testing/","title":"Testing","tags":[],"description":"","content":"Duo A, B \u0026amp; C Test your setup! TODO\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/","title":"Welcome","tags":[],"description":"","content":"RHTE 2023 Edge Lab Welcome, dear Red Hatter, in this Lab where you will discover a part of the Red Hat Edge offering.\nYou will play with the following technologies:\n ESP8266 MQTT AMQ Broker AMQ Streams (Apache Kafka Broker) OpenShift Camel-K  And if you plan to have a look under the hood, you will learn about:\n Quarkus ArgoCD Camel Kafka Streams Kafka MirrorMaker2  In this lab, you will be at the head of a shipping and delivery company, with multiple warehouses and you will deploy everything needed to: read the parcel RFID (using arduino and ESP32), send data to a MQTT broker over wifi, transform those data using Camel-K and send relevant events to the headquarter for reporting.\nAn application at the headquarter will display the parcels moving from one hub to another in realtime.\nTeam work and fun are expected ahead!\n"},{"uri":"https://RHTE-2023-Edge-Lab.github.io/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://RHTE-2023-Edge-Lab.github.io/tags/","title":"Tags","tags":[],"description":"","content":""}]